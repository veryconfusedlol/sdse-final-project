{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b028d8b1",
   "metadata": {},
   "source": [
    "# **SDSE Final Project: Predicting Car Fuel Efficiency with Machine Learning**\n",
    "Group #(insert number here)\n",
    "\n",
    "Our notebook attempts to predict a given car's **combined fuel efficiency (MPG)** based on information that is available **before** buying the car:\n",
    "\n",
    "- Make and type                 (SUV, sedan, etc.)\n",
    "- Drivetrain                    (FWD, AWD, etc.)\n",
    "- Engine displacement           (L)\n",
    "- Number of cylinders           (dimensinoless)\n",
    "- Transmission type             (automatic, manual, etc.)\n",
    "\n",
    "Why this matters:\n",
    "\n",
    "- Consumers can estimate real-world fuel costs for a car model even when independent test results are not widely available yet, such with new vehicle models and trims.\n",
    "- Dealerships and fleet managers can compare many options quickly based on expected efficiency.\n",
    "- Policy or sustainability teams can more immediately simulate how changing the mix of vehicles (more small engines, more hybrids, etc.) might affect fuel consumption and greenhouse/noise emissions.\n",
    "\n",
    "The notebook follows the outline specified for the project submissions in the lab session. \n",
    "\n",
    "0. Choose performance metric\n",
    "1. load data\n",
    "2. split off the test data set\n",
    "3. Choose the families of model and hyperparameter variations to test.\n",
    "4. Execute (train and evaluate) models\n",
    "5. Choose best model and evaluate with test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe9247",
   "metadata": {},
   "source": [
    "# 0. Performance metric:\n",
    "\n",
    "Since we are working with a regression model, we will be using the R^2 coefficient of determination as the metric to evaluate all our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173dbae3",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "In this section we:\n",
    "\n",
    "\n",
    "- **1.1**: import necessary libraries/packages\n",
    "    - **pandas / numpy** for data manipulation  \n",
    "    - **matplotlib** for plotting  \n",
    "    - **scikit‑learn** tools for preprocessing and linear regression  \n",
    "    - **TensorFlow / Keras** for building neural networks\n",
    "- read in the data\n",
    "- clean up the data\n",
    "- plot data\n",
    "- reduce number of classes in categories where there are too many (consolidation)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# !pip install tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in raw dataset with specs + fuel efficiency\n",
    "data = pd.read_csv(\"car_data.csv\")\n",
    "# print(\"First five rows of data: \\n\", data.head(5))     # Uncomment if you want a quick peak "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec68a62",
   "metadata": {},
   "source": [
    "**1.3: Defining Feature Columns and Target**\n",
    "\n",
    "Next, we decide which columns will be used as inputs (features) and which column is the output (target).\n",
    "\n",
    "- `categorical` lists all string‑based variables we might want to explore.\n",
    "- `numerical` contains the numeric engine characteristics that are important for fuel use.\n",
    "- `output` is the target: combined MPG.\n",
    "- `categorical_for_model` is a refined list of categorical columns used in the actual model.  \n",
    "  We keep a fixed set of five categorical variables as required by the project guidelines, and avoid overly specific identifiers which would be difficult to generalize well, such as the model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec86c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns are inputs (X) and which is the target (y)\n",
    "\n",
    "# Raw categorical columns present in the dataset\n",
    "categorical = ['type', 'drive', 'make', 'model', 'transmission']\n",
    "\n",
    "# Raw numerical columns\n",
    "numerical = ['cylinders', 'displacement']\n",
    "\n",
    "# Target we want to predict\n",
    "output = 'combination_mpg'\n",
    "\n",
    "# Categorical columns we’ll actually use in the model\n",
    "# (we drop 'model' here to avoid too many one-hot columns)\n",
    "categorical_for_model = ['type', 'drive', 'fuel_type', 'make', 'transmission']\n",
    "\n",
    "# Final feature matrix and target vector\n",
    "X = data[categorical_for_model + numerical]\n",
    "y = data[output]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eca377",
   "metadata": {},
   "source": [
    "**1.4: Data Cleaning and Preparation**\n",
    "\n",
    "Before training any model, our code handles missing values:\n",
    "\n",
    "1. **Drop rows with missing target**:  \n",
    "   If `combination_mpg` is missing, the data is unusable for supervised learning.\n",
    "\n",
    "2. **Impute numerical features with the mean**:  \n",
    "   This maintains a baseline that keeps all existing data while avoiding bias towards any existing value.\n",
    "\n",
    "3. **Impute categorical features with the mode** (most frequent category):  \n",
    "   This preserves the most likely class and keeps categories consistent.\n",
    "\n",
    "After cleaning, our code builds:\n",
    "\n",
    "- `feature_cols`: all columns that will be used as inputs\n",
    "- `X`: the feature matrix  \n",
    "- `y`: the target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "data = data.dropna(subset=[output])\n",
    "\n",
    "for col in numerical:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].fillna(data[col].mean())\n",
    "\n",
    "for col in categorical_for_model:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "\n",
    "# # Defining feature matrix X and target y\n",
    "# feature_cols = categorical_for_model + numerical\n",
    "# X = data[feature_cols]\n",
    "# y = data[output]\n",
    "\n",
    "# print(\"\\nFeature columns used for the model:\")\n",
    "# print(feature_cols)\n",
    "# print(f\"\\nNumber of samples after cleaning: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcccf415",
   "metadata": {},
   "source": [
    "**1.5: Consolidating categories with too many classes**\n",
    "\n",
    "We will consolidate the categories \"make\" and \"type\". We will ignore the \"model\" data in the model since each entry is a different model.\n",
    "\n",
    "The \"make\" category will be reduced to 3 classes by region of the company:\n",
    "1. **Asia:** kia, hyundai, genesis, mazda, honda, acura, subaru, mitsubishi, toyota, nissan, infiniti\n",
    "2. **Europe:** bmw, jaguar, mini, audi, land rover, volvo, volkswagen, aston martin, porsche, bentley, mercedes-benz\n",
    "3. **America:** chevrolet, jeep, gmc, ford, cadillac, buick, ram, roush performance, chrysler\n",
    "\n",
    "The \"type\" category will be reduced to 3 classes by size:\n",
    "1. **Small:** small sport utility vehicle, subcompact car, compact car, two seater, minicompact car, small station wagon\n",
    "2. **Medium:** midsize car, standard sport utility vehicle, small pickup truck, midsize station wagon\n",
    "3. **Large:** large car, minivan, standard pickup truck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94039b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining region lists for make region categories\n",
    "asia = [\"kia\", \"hyundai\", \"genesis\", \"mazda\", \"honda\", \"acura\",\n",
    "    \"subaru\", \"mitsubishi\", \"toyota\", \"nissan\", \"infiniti\"]\n",
    "\n",
    "europe = [\"bmw\", \"jaguar\", \"mini\", \"audi\", \"land rover\", \"volvo\",\n",
    "    \"volkswagen\", \"aston martin\", \"porsche\", \"bentley\", \"mercedes-benz\"]\n",
    "\n",
    "america = [\"chevrolet\", \"jeep\", \"gmc\", \"ford\", \"cadillac\", \"buick\",\n",
    "    \"ram\", \"roush performance\", \"chrysler\"]\n",
    "\n",
    "def consolidate_region(make):\n",
    "    if make in asia:\n",
    "        return \"asia\"\n",
    "    if make in europe:\n",
    "        return \"europe\"\n",
    "    if make in america:\n",
    "        return \"america\"\n",
    "    return \"other\"   # just in case\n",
    "\n",
    "# consolidating make data to make_region\n",
    "data[\"make_region\"] = data[\"make\"].apply(consolidate_region)\n",
    "\n",
    "small = [\"small sport utility vehicle\",\"subcompact car\",\"compact car\",\n",
    "            \"two seater\",\"minicompact car\",\"small station wagon\"]\n",
    "medium = [\"midsize car\", \"standard sport utility vehicle\", \n",
    "            \"small pickup truck\", \"midsize station wagon\"]\n",
    "large = [\"large car\", \"minivan\", \"standard pickup truck\"]\n",
    "\n",
    "def consolidate_size(type):\n",
    "    if type in small:\n",
    "        return \"small\"\n",
    "    if type in medium:\n",
    "        return \"medium\"\n",
    "    if type in large:\n",
    "        return \"large\"\n",
    "    return \"other\"\n",
    "        \n",
    "# consolidating type data to size\n",
    "data[\"size\"] = data[\"type\"].apply(consolidate_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31321adc",
   "metadata": {},
   "source": [
    "**1.6: Defining the final feature set for modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Selecting the final feature set for modeling -----\n",
    "\n",
    "# Consolidated list of categorical features we'll use.\n",
    "# Cleaned versions of raw columns so the model\n",
    "# doesn’t explode into too many one-hot encoded columns.\n",
    "categorical_for_model_consolidated = [\n",
    "    'size',\n",
    "    'drive',\n",
    "    'fuel_type',\n",
    "    'make_region',\n",
    "    'transmission'\n",
    "]\n",
    "\n",
    "# Combine categorical + numerical features to form the full input (X)\n",
    "feature_cols = categorical_for_model_consolidated + numerical\n",
    "\n",
    "# X contains only the columns we want the model to learn from\n",
    "X = data[feature_cols]\n",
    "\n",
    "# y is the target we want to predict — combined MPG\n",
    "y = data[output]\n",
    "\n",
    "# Helpful summary printout\n",
    "print(\"\\nFeature columns used for the model:\")\n",
    "print(feature_cols)\n",
    "\n",
    "print(f\"\\nNumber of samples after cleaning: {len(X)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d27c8a",
   "metadata": {},
   "source": [
    "## 2. Split off the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "# - Train: used to fit / tune models\n",
    "# - Test: held out until the very end to estimate real-world performance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,     # 20% of rows are used for final evaluation\n",
    "    random_state=42    # fixed seed for reproducible results\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389100a",
   "metadata": {},
   "source": [
    "**2.X: One-hot encoding**\n",
    "Machine learning models like linear regression work with numbers, not strings.  \n",
    "We therefore need to convert categorical features into a numeric format that a ML model can understand.\n",
    "\n",
    "We use:\n",
    "\n",
    "- **`ColumnTransformer` with `OneHotEncoder`**  \n",
    "  - Each categorical column is expanded into one binary column per category.\n",
    "  - `handle_unknown='ignore'` ensures the model can handle categories that only appear in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450bd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categorical columns and keep numeric ones as they are.\n",
    "# The preprocessor will be reused for all downstream models.\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # 'cat' transformer:\n",
    "        #   - OneHotEncoder turns each category into a binary column\n",
    "        #   - handle_unknown='ignore' lets us safely see unseen categories in test data\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_for_model_consolidated)\n",
    "    ],\n",
    "    remainder='passthrough'  # numerical columns go through unchanged\n",
    ")\n",
    "\n",
    "# 1. Fit preprocessor ONLY on training data to avoid data leakage\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# 2. Transform train and test sets into numeric matrices\n",
    "X_train_enc = preprocessor.transform(X_train)\n",
    "X_test_enc  = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a147e0d",
   "metadata": {},
   "source": [
    "## 3. Choose families of models & hyperparameter variations to test:\n",
    "\n",
    "1. Linear Regression\n",
    "    backward & forward feature reduction\n",
    "2. Ridge regression\n",
    "3. Neural Networks (MLP)  \n",
    "    3.1  \n",
    "    3.2  \n",
    "    3.3  \n",
    "    3.4  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410f406",
   "metadata": {},
   "source": [
    "## 4. Execute (train and evaluate) chosen models:\n",
    "\n",
    "**4.1: Linear Regression**\n",
    "\n",
    "We start with a plain **linear regression** model using all encoded features:\n",
    "- Input: one-hot encoded categorical features + numerical features  \n",
    "- Goal: find coefficients that best fit `combination_mpg` in a least-squares sense  \n",
    "- Metric: **R² on the test set**, which tells us how much of the variance in MPG is explained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4de5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a plain linear regression estimator\n",
    "model_LR = LinearRegression()\n",
    "\n",
    "# 2. Fit the model on the encoded training data\n",
    "model_LR.fit(X_train_enc, y_train)\n",
    "\n",
    "# 3. Predict on the held-out test data\n",
    "y_pred = model_LR.predict(X_test_enc)\n",
    "\n",
    "# 4. Compute R² on the test set (how much variance in y we explain)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\nLinear Regression R² Score on test set: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87595cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing linear-regression performance\n",
    "\n",
    "# 1. Predicted vs actual MPG\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "min_val = min(y_test.min(), y_pred.min())\n",
    "max_val = max(y_test.max(), y_pred.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], linestyle=\"--\")\n",
    "plt.xlabel(\"Actual MPG (test set)\")\n",
    "plt.ylabel(\"Predicted MPG\")\n",
    "plt.title(\"Linear Regression: Actual vs Predicted MPG\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Residuals plot (errors vs prediction)\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted MPG\")\n",
    "plt.ylabel(\"Residual (Actual - Predicted)\")\n",
    "plt.title(\"Linear Regression: Residuals vs Predicted\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd62ea",
   "metadata": {},
   "source": [
    "**4.1.1: Linear Regression with forward feature selection**\n",
    "\n",
    "We apply forward feature selection on top of linear regression:\n",
    "\n",
    "- Start with no features, then greedily add the feature that most improves cross-validated R².\n",
    "- Stop when we reach `n_select` features.\n",
    "- Retrain a linear regression model on this reduced feature set and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b62924d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forward Feature Selection Linear Regression R² Score on test set: 0.665\n",
      "\n",
      "Selected features:\n",
      "    cat__size_medium\n",
      "    cat__drive_4wd\n",
      "    cat__drive_awd\n",
      "    cat__drive_fwd\n",
      "    cat__fuel_type_electricity\n",
      "    cat__fuel_type_gas\n",
      "    cat__transmission_a\n",
      "    remainder__cylinders\n",
      "    remainder__displacement\n",
      "\n",
      "Removed features:\n",
      "    cat__size_large\n",
      "    cat__size_small\n",
      "    cat__drive_rwd\n",
      "    cat__fuel_type_diesel\n",
      "    cat__make_region_america\n",
      "    cat__make_region_asia\n",
      "    cat__make_region_europe\n",
      "    cat__transmission_m\n"
     ]
    }
   ],
   "source": [
    "n_select = X_train_enc.shape[1] - 8 # number of features to keep\n",
    "\n",
    "estimator = model_LR\n",
    "#forward selection\n",
    "# we could use the cv cross validation parameter as a hyperparameter to optimize/play with\n",
    "sfs_forward = SequentialFeatureSelector(estimator, n_features_to_select=n_select, direction='forward',cv=5)\n",
    "\n",
    "sfs_forward.fit(X_train_enc,y_train)\n",
    "# Extract mask of selected features\n",
    "selected_mask = sfs_forward.get_support()\n",
    "\n",
    "# Reduce train/test matrices\n",
    "X_train_fs = X_train_enc[:, selected_mask]\n",
    "X_test_fs  = X_test_enc[:, selected_mask]\n",
    "\n",
    "# Fit a new model on selected features\n",
    "lr_fs = LinearRegression()\n",
    "lr_fs.fit(X_train_fs, y_train)\n",
    "\n",
    "# Predict + evaluate\n",
    "y_pred_forward = lr_fs.predict(X_test_fs)\n",
    "r2_forward = r2_score(y_test, y_pred_forward)\n",
    "print(f\"\\nForward Feature Selection Linear Regression R² Score on test set: {r2_forward:.3f}\")\n",
    "\n",
    "#Get feature names\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "# print(feature_names)\n",
    "# Extract selected and removed names\n",
    "selected_features = feature_names[selected_mask]\n",
    "removed_features  = feature_names[~selected_mask]\n",
    "\n",
    "print(\"\\nSelected features:\")\n",
    "for f in selected_features:\n",
    "    print(\"   \", f)\n",
    "\n",
    "print(\"\\nRemoved features:\")\n",
    "for f in removed_features:\n",
    "    print(\"   \", f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2850de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d696651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(X_train_enc.shape[1])#-np.linspace(3,14,num=12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a760eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'sfs__n_features_to_select': (np.linspace(3,14,num=12)).astype(int)}\n",
    "\n",
    "model = Pipeline([('sfs',SequentialFeatureSelector(estimator, direction='forward', cv=5)),('lr',estimator)])\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, cv=5, scoring='r2')\n",
    "grid.fit(X_train_enc, y_train)\n",
    "\n",
    "n_select = grid.best_params_\n",
    "\n",
    "print(\"Best alpha after parameter optimization: alpha = \",n_select)\n",
    "print(\"Best cross-validation parameter sweep R²:\", grid.best_score_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d5361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running forward FS with optimal number of parameters to remove\n",
    "\n",
    "estimator = model_LR\n",
    "#forward selection\n",
    "# we could use the cv cross validation parameter as a hyperparameter to optimize/play with\n",
    "sfs_forward = SequentialFeatureSelector(estimator, n_features_to_select=n_select, direction='forward',cv=5)\n",
    "\n",
    "sfs_forward.fit(X_train_enc,y_train)\n",
    "# Extract mask of selected features\n",
    "selected_mask = sfs_forward.get_support()\n",
    "\n",
    "# Reduce train/test matrices\n",
    "X_train_fs = X_train_enc[:, selected_mask]\n",
    "X_test_fs  = X_test_enc[:, selected_mask]\n",
    "\n",
    "# Fit a new model on selected features\n",
    "lr_fs = LinearRegression()\n",
    "lr_fs.fit(X_train_fs, y_train)\n",
    "\n",
    "# Predict + evaluate\n",
    "y_pred_forward = lr_fs.predict(X_test_fs)\n",
    "r2_forward = r2_score(y_test, y_pred_forward)\n",
    "print(f\"\\nForward Feature Selection Linear Regression R² Score on test set: {r2_forward:.3f}\")\n",
    "\n",
    "#Get feature names\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "# print(feature_names)\n",
    "# Extract selected and removed names\n",
    "selected_features = feature_names[selected_mask]\n",
    "removed_features  = feature_names[~selected_mask]\n",
    "\n",
    "print(\"\\nSelected features:\")\n",
    "for f in selected_features:\n",
    "    print(\"   \", f)\n",
    "\n",
    "print(\"\\nRemoved features:\")\n",
    "for f in removed_features:\n",
    "    print(\"   \", f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7088a",
   "metadata": {},
   "source": [
    "**4.1.2 Backward Feature Selection LR**\n",
    "We also try Ridge Regression, which is linear regression with L2 penalty:\n",
    "\n",
    "- Adds a penalty on large coefficients to reduce overfitting.\n",
    "- Controlled by hyperparameter α.\n",
    "- We use cross-validation over several α values and choose the one that gives the best average R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_select = X_train_enc.shape[1] - 8 # number of features to keep\n",
    "\n",
    "estimator = model_LR\n",
    "# Backward selection\n",
    "# We could use the cv cross validation parameter as a hyperparameter to optimize/play with\n",
    "sfs_backward = SequentialFeatureSelector(estimator, n_features_to_select=n_select, direction='backward',cv=5)\n",
    "\n",
    "sfs_backward.fit(X_train_enc,y_train)\n",
    "# Extract mask of selected features\n",
    "selected_mask = sfs_backward.get_support()\n",
    "\n",
    "# Reduce train/test matrices\n",
    "X_train_fs = X_train_enc[:, selected_mask]\n",
    "X_test_fs  = X_test_enc[:, selected_mask]\n",
    "\n",
    "# Fit a new model on selected features\n",
    "lr_fs = LinearRegression()\n",
    "lr_fs.fit(X_train_fs, y_train)\n",
    "\n",
    "# Predict + evaluate\n",
    "y_pred_backward = lr_fs.predict(X_test_fs)\n",
    "r2_backward = r2_score(y_test, y_pred_backward)\n",
    "print(f\"\\nbackward Feature Selection Linear Regression R² Score on test set: {r2_backward:.3f}\")\n",
    "\n",
    "# Get feature names \n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "# print(feature_names)\n",
    "# Extract selected and removed names\n",
    "selected_features = feature_names[selected_mask]\n",
    "removed_features  = feature_names[~selected_mask]\n",
    "\n",
    "print(\"\\nSelected features:\")\n",
    "for f in selected_features:\n",
    "    print(\"   \", f)\n",
    "\n",
    "print(\"\\nRemoved features:\")\n",
    "for f in removed_features:\n",
    "    print(\"   \", f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a393273",
   "metadata": {},
   "source": [
    "**4.2 Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search for Ridge Regression (L2-regularized linear model)\n",
    "# We search over different alpha values using 5-fold cross-validation\n",
    "\n",
    "param_grid = {'alpha': [0.001,0.01, 0.1, 1, 10, 100]}\n",
    "param_grid = {'alpha': np.logspace(-2,-1,num=10)}\n",
    "\n",
    "model_ridge = Ridge()\n",
    "\n",
    "grid = GridSearchCV(model_ridge, param_grid, cv=5, scoring='r2')\n",
    "grid.fit(X_train_enc, y_train)\n",
    "\n",
    "\n",
    "best_alpha = grid.best_params_['alpha']\n",
    "\n",
    "print(\"Best alpha after parameter optimization: alpha = \", best_alpha)\n",
    "print(\"Best cross-validation parameter sweep R²:\", grid.best_score_)\n",
    "\n",
    "# creating model_ridge with the optimized alpha value\n",
    "model_ridge_best = Ridge(alpha=best_alpha)\n",
    "model_ridge_best.fit(X_train_enc, y_train)\n",
    "\n",
    "y_pred = model_ridge_best.predict(X_test_enc)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Best Ridge Test R²:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f93ee",
   "metadata": {},
   "source": [
    "**4.X: Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a032b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final input feature dimension:\", X_train_enc.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731f9de",
   "metadata": {},
   "source": [
    "**9. Neural Network Architectures**\n",
    "\n",
    "To explore non‑linear relationships, we implement four different neural network models:\n",
    "\n",
    "- **Model A: Simple**:  \n",
    "  - 1 hidden layer with 32 neurons (ReLU)  \n",
    "  - Good baseline, fast to train\n",
    "\n",
    "- **Model B: Deeper**:  \n",
    "  - Two hidden layers (64 → 32 units)  \n",
    "  - CAN model, more complex patterns\n",
    "\n",
    "- **Model C: Regularized with Dropout**:  \n",
    "  - Same idea as Model B but adds `Dropout(0.25)`  \n",
    "  - Helps reduce overfitting by randomly dropping neurons during training\n",
    "\n",
    "- **Model D: Wide with Batch Normalization**:  \n",
    "  - Two wide layers (128 → 64 units)  \n",
    "  - `BatchNormalization` after each hidd**en layer  \n",
    "  - Makes training more stable and can speed up convergence\n",
    "\n",
    "All models use:\n",
    "- **Optimizer**: Adam\n",
    "- **Loss**: Mean Squared Error (MSE)\n",
    "- **Metric**: Mean Absolute Error (MAE), easier to interpret as “average error in MPG”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be42cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN models\n",
    "\n",
    "def build_model_A(input_dim):\n",
    "    \"\"\"Model A - Simple 1-hidden-layer network.\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_dim=input_dim),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_B(input_dim):\n",
    "    \"\"\"Model B - Deeper network with two hidden layers.\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_C(input_dim):\n",
    "    \"\"\"Model C - Adds dropout for regularization.\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.25),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_D(input_dim):\n",
    "    \"\"\"Model D - Wide network using batch normalization.\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a712afee",
   "metadata": {},
   "source": [
    "We train each neural network using:\n",
    "\n",
    "- Early stopping (`EarlyStopping`) with:  \n",
    "  - `patience=10`: if validation loss does not improve for 10 epochs, training stops  \n",
    "  - `restore_best_weights=True`: we keep the model from the best epoch\n",
    "\n",
    "For each model we:\n",
    "\n",
    "1. Train on the encoded training data with a validation split.\n",
    "2. Evaluate on the encoded test set to obtain MSE  and MAE.\n",
    "3. Plot the training and validation loss curves to see whether the model is overfitting or underfitting.\n",
    "\n",
    "This makes the comparison between different architectures transparent and well‑documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58776906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate each neural network variant\n",
    "\n",
    "callbacks = [\n",
    "    # Early stopping stops training if val loss doesn't improve for 10 epochs,\n",
    "    # and restores the weights from the best epoch.\n",
    "    EarlyStopping(patience=10, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# Build one instance of each model architecture\n",
    "models = {\n",
    "    \"Model A\": build_model_A(X_train_enc.shape[1]),\n",
    "    \"Model B\": build_model_B(X_train_enc.shape[1]),\n",
    "    \"Model C\": build_model_C(X_train_enc.shape[1]),\n",
    "    \"Model D\": build_model_D(X_train_enc.shape[1]),\n",
    "}\n",
    "\n",
    "history = {}   # training curves (loss, val_loss)\n",
    "results = {}   # final test metrics\n",
    "\n",
    "for name, nn_model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    history[name] = nn_model.fit(\n",
    "        X_train_enc, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "    # Evaluate on test data and store MSE/MAE\n",
    "    test_mse, test_mae = nn_model.evaluate(X_test_enc, y_test, verbose=0)\n",
    "    results[name] = (test_mse, test_mae)\n",
    "    print(f\"{name} — Test MAE: {test_mae:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643d115",
   "metadata": {},
   "source": [
    "**Visualizing Training Curves**  \n",
    "Finally, we plot the training loss and validation loss for each model across epochs.\n",
    "\n",
    "Things to look for:\n",
    "\n",
    "- If validation loss starts increasing while training loss keeps decreasing, then the model is overfitted.  \n",
    "- If both losses are high and do not improve, then the model might be underpowered or features might not be informative enough\n",
    "\n",
    "These plots help justify which neural network architectures are the most appropriate for this prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c45728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves for each model\n",
    "for name in history:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(history[name].history['loss'], label='Train Loss')\n",
    "    plt.plot(history[name].history['val_loss'], label='Val Loss')\n",
    "    plt.title(name)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e3d554",
   "metadata": {},
   "source": [
    "## 5: Choose best model and evaluate with test data:\n",
    "\n",
    "In this final section we compare all candidate models on the held-out test set and pick a\n",
    "single “best” model for predicting combined MPG.\n",
    "\n",
    "We focus on:\n",
    "\n",
    "- **R²** – how much of the variance in MPG the model explains  \n",
    "- **MAE** – average absolute error in MPG (easier to interpret)  \n",
    "- **RMSE** – root mean squared error (penalizes large mistakes)\n",
    "\n",
    "Models we compare:\n",
    "\n",
    "1. **Baseline Linear Regression** (all encoded features)  \n",
    "2. **Ridge Regression** with the best α value (from Section 4.5)  \n",
    "3. **Neural Networks (Models A–D)** from Section 4.X  \n",
    "\n",
    "By evaluating all models on the **same test set**, we can see which one generalizes best,\n",
    "instead of just memorizing the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = []\n",
    "\n",
    "# 1. Plain Linear Regression\n",
    "y_pred_lr = model_LR.predict(X_test_enc)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "\n",
    "results_summary.append({\n",
    "    \"Model\": \"Linear Regression\",\n",
    "    \"Family\": \"Linear\",\n",
    "    \"R2\": r2_score(y_test, y_pred_lr),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_lr),\n",
    "    \"RMSE\": rmse_lr,\n",
    "})\n",
    "\n",
    "# 2. Best Ridge Regression\n",
    "# model_ridge_best = Ridge(alpha=best_alpha)\n",
    "model_ridge_best.fit(X_train_enc, y_train)\n",
    "y_pred_ridge = model_ridge_best.predict(X_test_enc)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "rmse_ridge = np.sqrt(mse_ridge)\n",
    "\n",
    "results_summary.append({\n",
    "    \"Model\": f\"Ridge (alpha={best_alpha})\",\n",
    "    \"Family\": \"Linear (regularized)\",\n",
    "    \"R2\": r2_score(y_test, y_pred_ridge),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_ridge),\n",
    "    \"RMSE\": rmse_ridge,\n",
    "})\n",
    "\n",
    "# 3. Neural Networks A–D\n",
    "for name, nn_model in models.items():\n",
    "    y_pred_nn = nn_model.predict(X_test_enc).flatten()\n",
    "    mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
    "    rmse_nn = np.sqrt(mse_nn)\n",
    "\n",
    "    results_summary.append({\n",
    "        \"Model\": name,\n",
    "        \"Family\": \"Neural Network\",\n",
    "        \"R2\": r2_score(y_test, y_pred_nn),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred_nn),\n",
    "        \"RMSE\": rmse_nn,\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_summary).sort_values(by=\"MAE\").reset_index(drop=True)\n",
    "\n",
    "print(\"Test-set performance of all models:\\n\")\n",
    "display(results_df)\n",
    "\n",
    "best_row = results_df.iloc[0]\n",
    "print(\"\\nBest overall model on the test set:\")\n",
    "print(f\"  {best_row['Model']} \"\n",
    "      f\"(Family: {best_row['Family']}) \"\n",
    "      f\"— R²={best_row['R2']:.3f}, MAE={best_row['MAE']:.3f}, RMSE={best_row['RMSE']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a141ac",
   "metadata": {},
   "source": [
    "The scores show how well each model handled the task of predicting a vehicle’s combined MPG:\n",
    "- R² tells us how much of the variation in fuel economy the model can explain — higher is better.\n",
    "- MAE gives the average size of the model’s mistakes in MPG, which is easy to understand in real-world terms.\n",
    "- RMSE punishes bigger errors more heavily and is a good indicator of how stable the model is across different kinds of cars.\n",
    "\n",
    "Comparing these models side-by-side reveals which approach generalized best rather than simply memorizing the training data.\n",
    "The best model delivers the most reliable MPG predictions and is the that would be best for deployment or continued focused refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db25b35d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
